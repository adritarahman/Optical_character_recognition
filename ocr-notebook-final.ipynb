{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14873887,"sourceType":"datasetVersion","datasetId":9515336},{"sourceId":14873928,"sourceType":"datasetVersion","datasetId":9515369}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nfrom glob import glob\nfrom torchmetrics import Accuracy\nfrom torchvision import models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:41:53.299858Z","iopub.execute_input":"2026-02-18T03:41:53.300162Z","iopub.status.idle":"2026-02-18T03:42:09.639544Z","shell.execute_reply.started":"2026-02-18T03:41:53.300128Z","shell.execute_reply":"2026-02-18T03:42:09.638935Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\nALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n            'v', 'w', 'x', 'y', 'z']\nALL_CHAR_SET = NUMBER + ALPHABET\nALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\nMAX_CAPTCHA = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:13.652639Z","iopub.execute_input":"2026-02-18T03:42:13.653369Z","iopub.status.idle":"2026-02-18T03:42:13.657654Z","shell.execute_reply.started":"2026-02-18T03:42:13.653336Z","shell.execute_reply":"2026-02-18T03:42:13.656926Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class OCRDataset(Dataset):\n    def __init__(self, image_files, transform=None):\n        self.image_files = image_files\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def encode(self, char):\n        onehot = [0] * ALL_CHAR_SET_LEN\n        idx = ALL_CHAR_SET.index(char)\n        onehot[idx] += 1\n        return onehot\n\n    def __getitem__(self, idx):\n        image_file = self.image_files[idx]\n        img = Image.open(image_file)\n        img = img.convert('L')\n        label = image_file.split(os.sep)[-1][:-4]\n        label_oh = []\n        for i in label[:MAX_CAPTCHA]:  \n            label_oh += self.encode(i)\n        \n        label_oh += [0] * (ALL_CHAR_SET_LEN * (MAX_CAPTCHA - len(label)))\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, np.array(label_oh), label\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:17.381687Z","iopub.execute_input":"2026-02-18T03:42:17.382258Z","iopub.status.idle":"2026-02-18T03:42:17.388380Z","shell.execute_reply.started":"2026-02-18T03:42:17.382227Z","shell.execute_reply":"2026-02-18T03:42:17.387714Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class OCRDataModule(pl.LightningDataModule):\n    \n    def __init__(self, batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n\n        self.transform = transforms.Compose([\n            transforms.Resize([64, 128]),\n            transforms.ToTensor(),\n        ])\n\n    def setup(self, stage=None):\n        train_image_files = glob('/kaggle/input/datasets/adritarahman3/ocr-dataset-1/OCR/Train/*.png')\n        test_image_files = glob('/kaggle/input/datasets/adritarahman3/ocr-dataset-1/OCR/Test/*.png')\n\n        self.train_dataset = OCRDataset(\n            train_image_files,\n            transform=self.transform\n        )\n\n        self.val_dataset = OCRDataset(\n            test_image_files,\n            transform=self.transform\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n        )\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:21.732225Z","iopub.execute_input":"2026-02-18T03:42:21.732502Z","iopub.status.idle":"2026-02-18T03:42:21.738407Z","shell.execute_reply.started":"2026-02-18T03:42:21.732476Z","shell.execute_reply":"2026-02-18T03:42:21.737707Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_module = OCRDataModule(\n    batch_size=32\n)\n\ndata_module.setup()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:29.132836Z","iopub.execute_input":"2026-02-18T03:42:29.133167Z","iopub.status.idle":"2026-02-18T03:42:29.171381Z","shell.execute_reply.started":"2026-02-18T03:42:29.133140Z","shell.execute_reply":"2026-02-18T03:42:29.170775Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nclass OCRModel(pl.LightningModule):\n    def __init__(self, num_chars=ALL_CHAR_SET_LEN, max_length=MAX_CAPTCHA):\n        super(OCRModel, self).__init__()\n        self.save_hyperparameters()\n        self.char_set = ALL_CHAR_SET\n\n        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  \n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n\n        in_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_chars * max_length)\n        )\n\n        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_chars)\n        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_chars)\n\n        self.inference_transform = transforms.Compose([\n            transforms.Resize([64, 128]),\n            transforms.ToTensor(),\n        ])\n\n    def forward(self, x):\n        out = self.resnet(x)\n        return out.view(-1, self.hparams.max_length, self.hparams.num_chars)\n\n    def training_step(self, batch, batch_idx):\n        x, y, _ = batch\n        y_hat = self(x)\n        \n        batch_size = x.size(0)\n        y_hat = y_hat.view(batch_size * self.hparams.max_length, self.hparams.num_chars)\n        y = y.view(batch_size, self.hparams.max_length, self.hparams.num_chars)\n        y = y.argmax(dim=-1).view(-1)  \n\n        loss = F.cross_entropy(y_hat, y)\n\n        self.train_accuracy(y_hat.softmax(dim=-1), y)\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_acc', self.train_accuracy, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y, _ = batch\n        y_hat = self(x)\n\n        batch_size = x.size(0)\n        y_hat = y_hat.view(batch_size * self.hparams.max_length, self.hparams.num_chars)\n        y = y.view(batch_size, self.hparams.max_length, self.hparams.num_chars)\n        y = y.argmax(dim=-1).view(-1)  \n\n        loss = F.cross_entropy(y_hat, y)\n\n        self.val_accuracy(y_hat.softmax(dim=-1), y)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', self.val_accuracy, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        return {\n            'optimizer': optimizer,\n            'lr_scheduler': scheduler\n        }\n\n    def predict_image(self, image_path):\n        \n        img = Image.open(image_path).convert('L')\n        img = self.inference_transform(img)\n        img = img.unsqueeze(0) \n\n        img = img.to(self.device)\n        \n        self.eval()\n        with torch.no_grad():\n            output = self(img)  \n            output = output.softmax(dim=-1)  \n            pred_indices = output.argmax(dim=-1)  \n\n        pred_text = ''.join(self.char_set[idx] for idx in pred_indices[0])\n        return pred_text\n      \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:33.661567Z","iopub.execute_input":"2026-02-18T03:42:33.662231Z","iopub.status.idle":"2026-02-18T03:42:33.673823Z","shell.execute_reply.started":"2026-02-18T03:42:33.662199Z","shell.execute_reply":"2026-02-18T03:42:33.673107Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = OCRModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:42.589307Z","iopub.execute_input":"2026-02-18T03:42:42.589894Z","iopub.status.idle":"2026-02-18T03:42:43.196333Z","shell.execute_reply.started":"2026-02-18T03:42:42.589864Z","shell.execute_reply":"2026-02-18T03:42:43.195587Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 173MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"trainer = pl.Trainer(\n        max_epochs=50,\n)\ntrainer.fit(model, data_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:46.620622Z","iopub.execute_input":"2026-02-18T03:42:46.621196Z","iopub.status.idle":"2026-02-18T03:44:18.743539Z","shell.execute_reply.started":"2026-02-18T03:42:46.621165Z","shell.execute_reply":"2026-02-18T03:44:18.742867Z"}},"outputs":[{"name":"stderr","text":"Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n2026-02-18 03:42:49.248180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771386169.447783      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771386169.510781      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771386170.026750      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771386170.026801      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771386170.026803      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771386170.026806      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ resnet         â”‚ ResNet             â”‚ 11.5 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ train_accuracy â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ val_accuracy   â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ resnet         â”‚ ResNet             â”‚ 11.5 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ train_accuracy â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ val_accuracy   â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 11.5 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 11.5 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 46                                                                         \n\u001b[1mModules in train mode\u001b[0m: 74                                                                                          \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 11.5 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 11.5 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 46                                                                         \n<span style=\"font-weight: bold\">Modules in train mode</span>: 74                                                                                          \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ec61f911df44d47bb685cd555ada69e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \nfrom an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., \nbatch_size=batch_size)`.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \nfrom an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., \nbatch_size=batch_size)`.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \nfrom an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., \nbatch_size=batch_size)`.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \nfrom an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., \nbatch_size=batch_size)`.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches \n(11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if\nyou want to see logs for the training epoch.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches \n(11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if\nyou want to see logs for the training epoch.\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=50` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"image_file = '/kaggle/input/datasets/adritarahman3/ocr-dataset-1/OCR/Test/1odm.png'\npred_text = model.predict_image(image_file)\nprint(pred_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:50:39.827468Z","iopub.execute_input":"2026-02-18T03:50:39.828202Z","iopub.status.idle":"2026-02-18T03:50:40.003227Z","shell.execute_reply.started":"2026-02-18T03:50:39.828167Z","shell.execute_reply":"2026-02-18T03:50:40.002467Z"}},"outputs":[{"name":"stdout","text":"1odm\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"pip install mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:52:53.627421Z","iopub.execute_input":"2026-02-18T03:52:53.627769Z","iopub.status.idle":"2026-02-18T03:53:06.630515Z","shell.execute_reply.started":"2026-02-18T03:52:53.627739Z","shell.execute_reply":"2026-02-18T03:53:06.629757Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-skinny==3.9.0 (from mlflow)\n  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\nCollecting mlflow-tracing==3.9.0 (from mlflow)\n  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.0)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (46.0.3)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting huey<3,>=2.5.4 (from mlflow)\n  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (22.0.0)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.15.3)\nCollecting skops<1 (from mlflow)\n  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n  Downloading databricks_sdk-0.89.0-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.123.10)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.45)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nCollecting packaging<26 (from mlflow-skinny==3.9.0->mlflow)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.29.5)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.5)\nRequirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.1.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.5)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.38.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.6.3)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: prettytable>=3.9 in /usr/local/lib/python3.12/dist-packages (from skops<1->mlflow) (3.16.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.23)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.47.0)\nRequirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.50.0)\nRequirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.58b0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.9->skops<1->mlflow) (0.2.14)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.6.1)\nDownloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skops-0.13.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.89.0-py3-none-any.whl (798 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading packaging-25.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huey, packaging, graphql-core, gunicorn, graphql-relay, skops, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n  Attempting uninstall: packaging\n    Found existing installation: packaging 26.0rc2\n    Uninstalling packaging-26.0rc2:\n      Successfully uninstalled packaging-26.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Flask-CORS-6.0.2 databricks-sdk-0.89.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 packaging-25.0 skops-0.13.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"BATCH_SIZE=32\nMAX_EPOCHS=50\nALL_CHAR_SET_LEN=36\nMAX_CAPTCHA=4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:53:18.769393Z","iopub.execute_input":"2026-02-18T03:53:18.769787Z","iopub.status.idle":"2026-02-18T03:53:18.774530Z","shell.execute_reply.started":"2026-02-18T03:53:18.769747Z","shell.execute_reply":"2026-02-18T03:53:18.773983Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import os\nimport shutil\nimport mlflow\nimport mlflow.pytorch\nimport torch\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import MLFlowLogger\nfrom IPython.display import FileLink\n\n\nMLFLOW_DIR = \"/kaggle/working/mlruns\"\nARTIFACT_PATH = \"captcha_ocr_outputs\"\nSOURCE_CODE_PATH = \"/kaggle/input/datasets/adritarahman3/ocr-notebook-1\" \n\nif not os.path.exists(MLFLOW_DIR):\n    os.makedirs(MLFLOW_DIR)\n\n\nmlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\nmlflow.set_experiment(\"Captcha_ResNet_OCR\")\n\n\nmlf_logger = MLFlowLogger(\n    experiment_name=\"Captcha_ResNet_OCR\",\n    tracking_uri=f\"file://{MLFLOW_DIR}\"\n)\n\n\nmodel = OCRModel(num_chars=ALL_CHAR_SET_LEN, max_length=MAX_CAPTCHA)\ndata_module = OCRDataModule(batch_size=BATCH_SIZE)\ndata_module.setup()\n\n\ntrainer = pl.Trainer(\n    max_epochs=MAX_EPOCHS,\n    accelerator=\"auto\",\n    devices=1,\n    logger=mlf_logger,\n    log_every_n_steps=10\n)\n\n\ntrainer.fit(model, data_module)\nrun_id = mlf_logger.run_id\n\n\nwith mlflow.start_run(run_id=run_id):\n    \n    val_results = trainer.validate(model, datamodule=data_module)\n    if val_results:\n        for k, v in val_results[0].items():\n            mlflow.log_metric(k, v)\n\n    \n    local_weights_name = \"model_weights.pth\"\n    torch.save(model.state_dict(), local_weights_name)\n    mlflow.log_artifact(local_weights_name, artifact_path=ARTIFACT_PATH)\n\n    \n    if os.path.exists(SOURCE_CODE_PATH):\n        mlflow.log_artifact(SOURCE_CODE_PATH, artifact_path=\"source_code\")\n    \n   \n    mlflow.pytorch.log_model(model, artifact_path=\"model_flavor\")\n\n    \n    print(f\"âœ… Weights and Notebook saved in mlruns/{run_id}/artifacts\")\n\n\nexperiment_id = mlflow.get_experiment_by_name(\"Captcha_ResNet_OCR\").experiment_id\nartifact_src = f\"{MLFLOW_DIR}/{experiment_id}/{run_id}/artifacts\"\nzip_name = \"/kaggle/working/ocr_project_results\"\n\nshutil.make_archive(zip_name, 'zip', artifact_src)\n\ndisplay(FileLink(zip_name + \".zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T04:04:58.986176Z","iopub.execute_input":"2026-02-18T04:04:58.986924Z","iopub.status.idle":"2026-02-18T04:06:32.821386Z","shell.execute_reply.started":"2026-02-18T04:04:58.986877Z","shell.execute_reply":"2026-02-18T04:06:32.820711Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, store_uri)\n2026/02/18 04:05:02 INFO mlflow.tracking.fluent: Experiment with name 'Captcha_ResNet_OCR' does not exist. Creating a new experiment.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ resnet         â”‚ ResNet             â”‚ 11.5 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ train_accuracy â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ val_accuracy   â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ resnet         â”‚ ResNet             â”‚ 11.5 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ train_accuracy â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ val_accuracy   â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 11.5 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 11.5 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 46                                                                         \n\u001b[1mModules in train mode\u001b[0m: 74                                                                                          \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 11.5 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 11.5 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 46                                                                         \n<span style=\"font-weight: bold\">Modules in train mode</span>: 74                                                                                          \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8deb32822e046fdacbee0facd04475e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The \n'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n`num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=50` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stderr","text":"LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20260826db81434ab056d533ba03227f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5857142806053162    \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ”‚\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   1.8107324838638306    \u001b[0m\u001b[35m \u001b[0mâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\">      Validate metric      </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5857142806053162     </span>â”‚\nâ”‚<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    1.8107324838638306     </span>â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stderr","text":"2026/02/18 04:06:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n2026/02/18 04:06:11 WARNING mlflow.pytorch: Saving pytorch model by Pickle or CloudPickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is to set 'export_model' to True to save the pytorch model using the safe graph model format.\n2026/02/18 04:06:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/02/18 04:06:30 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Weights and Notebook saved in mlruns/c724deacab2640f8a76495efa10fa90f/artifacts\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ocr_project_results.zip","text/html":"<a href='/kaggle/working/ocr_project_results.zip' target='_blank'>/kaggle/working/ocr_project_results.zip</a><br>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\nshutil.make_archive('mlruns', 'zip', '/kaggle/working/mlruns')\n\nFileLink(r'mlruns.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T04:20:59.260874Z","iopub.execute_input":"2026-02-18T04:20:59.261485Z","iopub.status.idle":"2026-02-18T04:21:10.262841Z","shell.execute_reply.started":"2026-02-18T04:20:59.261451Z","shell.execute_reply":"2026-02-18T04:21:10.262118Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/mlruns.zip","text/html":"<a href='mlruns.zip' target='_blank'>mlruns.zip</a><br>"},"metadata":{}}],"execution_count":13}]}